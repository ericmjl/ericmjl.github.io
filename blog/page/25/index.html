<!doctype html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <!-- Bootstrap v4beta Imports -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">

    <style media="screen">
        body {
            padding-top: 70px;
            padding-bottom: 70px;
        }
    </style>

    <!-- Syntax Highlighter. Use both pygments and hl.js. -->
    <link rel="stylesheet" href="../../../static/pygments.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- Google Analytics -->
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-12498603-2', 'auto');
        ga('send', 'pageview');
    </script>

    <!-- ClustrMaps Tracking -->
    <!-- <script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=nhKoDpoTjWz4pC6CwI-fSy4hPoJ1uXwTLCfMCT3OK_8"></script> -->

    <!-- FontAwesome embed -->
    <script src="https://use.fontawesome.com/cb9dbe8e41.js"></script>
</head>

<title>Blog - Eric J. Ma's Personal Site</title>
<body class="body">
    <nav class="navbar navbar-expand-sm navbar-light fixed-top bg-light">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#local-links" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="local-links">
            <ul class="navbar-nav mr-auto">
                
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="fa fa-home" aria-hidden="true"></i> Home</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/resume"><i class="fa fa-file-text" aria-hidden="true"></i> Resume</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/blog"><i class="fa fa-rss" aria-hidden="true"></i> Blog</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/open-source"><i class="fa fa-code" aria-hidden="true"></i> Open Source</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/projects"><i class="fa fa-briefcase" aria-hidden="true"></i> Projects</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/talks"><i class="fa fa-microphone" aria-hidden="true"></i> Talks</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/teaching"><i class="fa fa-university" aria-hidden="true"></i> Teaching</a>
                </li>
                
            </ul>
        </div>
    </nav>
    <div class="container">
        
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>
  
    <h1><a href="../../../blog/2016/2/9/scikit-learn-tutorial/">scikit-learn tutorial</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2016-02-09
  </p>
  <p>This past Monday, I led a hands-on session at the <a href="http://broadinstitute.org">Broad Institute</a>, showing how to use the <a href="http://scikit-learn.org">scikit-learn</a> API, as well as common coding patterns for running machine learning algorithms on the data.</p>
<p><a href="http://www.ericmajinglong.com/wp-content/uploads/2016/02/IMG_20160208_132009.jpg" rel="attachment wp-att-525"><img class="aligncenter wp-image-525 size-large" src="http://www.ericmajinglong.com/wp-content/uploads/2016/02/IMG_20160208_132009-1024x768.jpg" alt="IMG_20160208_132009" width="640" height="480" /></a></p>
<p>First off, I was totally surprised at how many people signed up for the event - it "sold out" (tickets were free) within 3 hours of opening registration. I was quite floored - and I know it's not because I'm some famous dude who knows ML algorithms. Rather, it told me and my co-organizers that there is most certainly great demand here for this topic, and it should be run again.</p>
<p>I found it to be a great opportunity to put some of my <a href="http://software-carpentry.org">Software Carpentry</a>/<a href="http://www.datacarpentry.org">Data Carpentry</a> tools to use. For example, we used sticky notes to indicate class progress (we used blue for "all done", and red for "need help"). I also tried to ensure that participants could walk away from the tutorial knowing how to do something that they could use immediately in their research.</p>
<p>The examples I used (<a href="http://github.com/ericmjl/scikit-learn-tutorial/">hosted openly on Github</a>) were based on transforming sequence information into a sequence feature matrix, which is then fed into a selected machine learning algorithm. I think this seemed to suit the crowd, but I would love to use different examples as well, for example microbiome data or transcriptomics data.</p>
<p>Feedback given by the participants was overall quite positive. To some, I could have explained things a bit more clearly, which I could recognize as an area I will need to improve on for delivering a second round. Others loved the hands-on instruction; in their feedback it was just the right delivery format for the workshop.</p>
<p>One participant asked me, "Why do you host these workshops?" (I had done one on statistics with some fellow BE colleagues.) I hadn't thought much about that question, so my instinctive response was, "For fun - I'm finding ways to share knowledge, for the benefit of the community." I stand by that thought, as I think it's important for knowledge-bearers to make copies of their knowledge, for the sake of giving back to the community. Yet, stemming from knowledge of myself, I also think that sharing programming knowledge around is an insurance policy against personal stagnation. Put in simple terms, if others know how to wield the tools that I know how to do, then I had better continue levelling up my skill to stand out. It also gets boring and sometimes frustrating person after a while being the "go-to" person for things ML-related or computing-related; it means I can't devote time to exploring new things. So sharing is fun, and is an insurance policy against boredom and frustration - why not share then? :)</p>
<p>All in all, looking forward to reporting on the workshop at the next Broad NextGen meeting, and hosting another iteration at a later time!</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2016/2/9/scikit-learn-tutorial/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>
  
    <h1><a href="../../../blog/2015/12/3/reticulate-evolution-and-microbial-ecology/">Reticulate Evolution and Microbial Ecology</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2015-12-03
  </p>
  <p>I am happy to announce that, with my advisor's (Jon Runstadler, MIT) approval, I've uploaded my first 1st-author paper to <a href="http://biorxiv.org/content/early/2015/12/02/033514">BioRXiv</a>. This may sound surprising, to document and write about the paper pre-peer review, rather than after being formally accepted after peer-preview in a journal. This choice is borne out of two desires.</p>
<p>Firstly, I am fed up with having the editorial process decide whether my work can be sent for peer evaluation, based on some perceived notion of broad impact or editorial alignment. This manuscript has gone through four editorial rejections and (hopefully not) counting…  I acknowledge that “4” is a small number, but my patience and tolerance level for bureaucratic delays is very low, and I think the editorial process is a big reason delaying the work from review. After internal review and public presentation in talks and posters, peer review and evaluation is the final step in getting my work evaluated in the public domain. Really, it’s about getting feedback on whether what I’ve worked on constitutes sufficiently rigorous scientific work or not. I’d like to know that earlier rather than later, and I do not believe that editors should be the gatekeepers of this process. Pre-print servers let me release the work to the public domain without tough barriers to break down, which help me achieve this goal.</p>
<p>Secondly, I’m really, like <em>really</em>, excited about the results in this paper, regardless of what others think about its impact. It’s hard to contain this PhD candidate’s enthusiasm for his work. I’m particularly proud of the work done here, especially the code written from scratch to answer this question, with everything written and designed to be reproducible. Thus, much like an artist has a natural drive towards showcasing work s/he is proud of, I have this desire to get it out there. I hope you enjoy it.</p>
<h2 id="manuscript-in-brief">Manuscript in Brief</h2><p><strong>Title:</strong> Reticulate evolution is favoured in microbial niche switching.</p>
<p><strong>Question being answered:</strong> Can we measure how important reticulate evolutionary processes that result in gene exchange are in enabling microbes to switch between ecological niches?</p>
<p><strong>tl;dr answer</strong>: Yes we can, and when switching ecological niches, the ability to exchange genes is more important the greater the difference between the niches.</p>
<p><strong>Definitions:</strong>
I think some definitions are required before I proceed.</p>
<ul>
<li><em>Reticulate evolution</em>: A non-tree-like evolutionary trajectory. It involves processes like recombination, reassortment, horizontal gene transfer, sexual reproduction etc. In this paper, we detect reassortment amongst influenza A viruses.</li>
<li><em>Ecological niche</em>: Ecology is the study of organisms and their interactions with one another and their environment. Organisms occupy certain niches - such as particular habitats, producing and consuming particular combinations of nutrients. In this paper, an ecological niche is defined as a particular host species of the influenza A virus.</li>
<li><em>Switching</em>: When a microbe switches ecological niches, it has either entered a new ecological niche - different environment, a new set of host species it interacts with etc. In this paper, we define niche switching as switching between different hosts, as the host is the environment for the influenza A virus.</li>
</ul>
<p><strong>Brief Background:</strong></p>
<p>In the field of ecology, there’s this idea that gene exchange between two microbes can lead to genetic diversity, and lead to fitness advantages in new environments. To the best of my knowledge, this idea has not been tested explicitly (and I am happy to be corrected on this). In our paper, we sought to <strong>test whether, in switching between different host species, gene shuffling between influenza A viruses was more prevalent than clonal transmission</strong>. If so, it would allude to a broader principle that reticulate evolutionary events are important when microbes change ecological niches.</p>
<p><strong>Why should we care?</strong></p>
<p>Why should we care about this problem that, seemingly, only microbes have to deal with? Well, we know that microbes and human health intersect, and this is borne out in the scientific literature. Specifically with the influenza virus, every new pandemic virus that has emerged in human populations has been shown to be a reassortant virus. It looks quite clear to me that reticulate evolution intersects with host and microbe ecology, impacting human health.</p>
<p><strong>How did we answer the scientific question at hand?</strong></p>
<p>To do this, we used data from the Influenza Research Database, which houses influenza sequence data augmented with collection date and host species metadata. This makes it a really suitable dataset to answer the broader question, “Is reticulate evolution is favoured in ecological niche switches?”. This is because of a few reasons. Firstly, it is a densely-sampled dataset with a global scope, which allows us to detect rare reassortment events. Secondly, we can trace source-sink paths through different host species, by using time and genetic data. Finally, influenza can undergo reassortment, which is its reticulate evolutionary process.</p>
<p>To answer the broader question, we first had to figure out which viruses were reassortant, and where they came from. Our method involves using a phylogenetic heuristic method, which has been previously published, and which we modified to detect reticulate evolutionary events. We basically ask, “What are the sources of segments for each influenza virus?” We try to make sure that all segments for one “sink” virus isolate are traceable back to one older “source” isolate, ensuring that the two isolates are of maximal similarity possible across all 8 segments. That sink virus would be denoted as a clonally transmitted virus, resulting from “<strong>clonal descent</strong>”. However, if a “source pair”, i.e. two viruses donating part of their genome, could improve the summed similarity score, then we denote that sink virus as the reassortant virus, resulting from “<strong>reassortment descent</strong>”.</p>
<p>How do we represent the data? This is done as a directed graph of influenza A virus isolates (nodes), and two types of descent (edges): clonal and reassortment. If there are more than one plausible clonal or reassortment source, then the corresponding edges are weighted accordingly, such that the sum of edges into one node is equal to 1. This encodes our knowledge of one virus being the result of one possible reassortment event, or one clonal transmission event.</p>
<p><strong>What did we find?</strong></p>
<p>We show in our supplementary data that our method and representation together well-approximates the phylogenetic relationships calculated by more sophisticated Bayesian methods, and that it captures known patterns of influenza transmission and ‘famous’ reassortant viruses. In some sense, the method we adapted can scale better compared to Bayesian methods, especially when the number of viral taxa are large, and I think it can represent reticulate events better than trees. However, I will state that Bayesian phylogenetic inference is still the gold-standard for representing evolution on a single gene/trait.</p>
<p>We then wanted to assess whether reassortment was over-represented when hosts were identical or different. To calculate this, we looked all edges where the source and sink hosts were identical, and compared them to edges where the source and sink hosts were different. When source and sink hosts were different, the proportion of edges that represented reassortment events were over-represented compared to a null model of host species labels on the viral nodes being permuted. When they were identical, reassortment was under-represented compared to the null.</p>
<p>We then wanted to know whether at different host group interfaces, reassortment was over- or under-represented compared to a null model. We found that once again, reassortment was under-represented compared to the null when the virus jumped between hosts of the same group, and over-represented when jumping between different host groups.</p>
<p>Finally, we wanted to know whether the degree of dissimilarity between two hosts mattered. We used data from the Barcode of Life Database to identify the host’s cytochrome oxidase I genes, and measured percentage dissimilarity as a metric of the degree of host dissimilarity. Here, we found that as hosts become more different, reassortment was more prominently featured during those switches.</p>
<p><strong>So what does this all mean?</strong></p>
<p>All-in-all, we find that reticulate evolutionary processes are indeed important in microbe ecology. Scientifically, I think the novelty here lies in quantitatively defining the importance of the ability to shuffle genes when a microbe changes ecological contexts, with the change quantitatively defined as well. From a public health perspective, if I were allowed to put on my “divergent thinking” hat, one direct application of this knowledge would be to quantify the “reticulate potential” of a pathogen - how easily it can acquire and share genes. This may inform which pathogens we would want to perform deeper disease surveillance on.</p>
<p><strong>Where can I view this paper, code, and data?</strong></p>
<p>In line with open science principles, we have uploaded all of the code used in the analysis to Zenodo. Their DOIs are referenced in the manuscript.</p>
<p>The paper is available <a href="http://biorxiv.org/content/early/2015/12/02/033514">here</a> on BioRXiv.</p>
<p>The data are publicly available on the <a href="../../../blog/2015/12/3/reticulate-evolution-and-microbial-ecology/www.fludb.org">Influenza Research Database</a>.</p>
<p>I hope you enjoy reading it!</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2015/12/3/reticulate-evolution-and-microbial-ecology/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>
  
    <h1><a href="../../../blog/2015/11/28/profiling-pypy-vs-python-for-agent-based-simulation/">Profiling PyPy vs. Python for Agent-Based Simulation</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2015-11-28
  </p>
  <h2 id="outline">Outline</h2><ol>
<li>Introduction:<ol>
<li>Motivation</li>
<li>Model description</li>
<li>Link to code</li>
</ol>
</li>
<li>Environment Setup</li>
<li>Performance<ol>
<li>Python vs. PyPy on one parameter set.</li>
<li>Vary number of hosts, record time.</li>
</ol>
</li>
</ol>
<h2 id="introduction">Introduction</h2><p>As part of my PhD dissertation, I wanted to investigate the role of host ecology on the generation of reassortant viruses. Knowing myself to be a fairly algebra-blind person, I decided that an agent-based model (ABM) was going to be much more manageable than writing ODEs. (Actually, the real reason is that I"m modelling discrete states, rather than continuous states, but yes, I will admit that I do take longer than your average programmer with algebra.)</p>
<h3 id="model-description">Model Description</h3><p>Starting with our intuition of host-pathogen interactions, I implemented a custom ABM using Python classes - "Hosts" and "Viruses".</p>
<h4 id="viruses">Viruses</h4><p>"Viruses" had two segments, representing a segmented virus (like the Influenza or Lassa virus), each with a color (red or blue), and can infect Hosts (which are likewise red or blue). Viruses that are of a particular color prefer to infect hosts of the same color, but can still infect hosts of of a different colour, just at a lower probability. If two viruses are present in the same host, then there can be, at some small probability, the opportunity for gene sharing to occur.</p>
<p>One of the virus' segments determines host immunity; if the virus encounters a host which has immunity against its color, then the probability of infection drastically decreases, and it is likely that the virus will eventually be cleared.</p>
<h4 id="hosts">Hosts</h4><p>"Hosts" are where viruses replicate. Hosts gain immunity to one of the segment's colors, after a set number of days of infection. When a host gains immunity to a particular virus color, it can much more successfully fend off a new infection with that same color. Hosts also interact with one another. They may have a strong preference for a host of the same color, a.k.a. homophily.</p>
<h3 id="code">Code</h3><p>My code for the simulations can be found on <a href="http://github.com/ericmjl/reassortment-simulator">this Github repository</a>. The details of the simulation are still a work in progress, as these ideas are still early stage. My point on this blog post here will be to try to compare PyPy against CPython on performance. However, I do welcome further comments on the modelling, if you've taken the time to read through my code.</p>
<p>Code for the statistical draws can be found on <a href="http://github.com/ericmjl/pypy_stats">this other Github repository</a>.</p>
<p><h2 id="environment-setup">Environment Setup</h2>
My CPython environment is managed by <code>conda</code>. (Highly recommended! Download <a href="https://www.continuum.io/downloads">here</a>. Make sure to get Python 3!)</p>
<p>I installed <code>pypy</code> and <code>pypy3</code> under my home directory on Ubuntu Linux, and ensured that my bash shell <code>$PATH</code> variable also pointed to <code>~/pypy[3]/bin</code>.</p>
<h2 id="performance">Performance</h2><p>Let's take a look at the performance of the CPython vs. PyPy using pure-Python code.</p>
<h3 id="default-parameters">Default parameters</h3><p>I first started with 1000 agents in the simulation, with the simulation running for 150 time steps.</p>
<p>Under these circumstances, on an old Asus U30J with 8GB RAM and an SSD hard disk, Core i3 2.27GHz, executing the simulation with PyPy required only 13.4 seconds, while executing with CPython required 110.5 seconds. 10x speedup.</p>
<h3 id="varying-number-of-hosts-in-the-model">Varying number of hosts in the model</h3><p>I wanted to measure the time complexity of the simulation as a function of the number of hosts. Therefore, I varied the number of hosts from 100 to 1600, in steps of 300.</p>
<p>Partial (mostly because of laziness) results are tabulated below. (Yes, this degree of laziness would never fly in grad school.)</p>
<table><colgroup> <col /> <col /> <col /> <col /> <col /> <col /> <col /> </colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Agents</th>
<th style="text-align: left;">PyPy Trial 1</th>
<th style="text-align: left;">PyPy Trial 2</th>
<th style="text-align: left;">PyPy Trial 3</th>
<th style="text-align: left;">CPython Trial 1</th>
<th style="text-align: left;">CPython Trial 2</th>
<th style="text-align: left;">CPython Trial 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1000</td>
<td style="text-align: left;">13.4</td>
<td style="text-align: left;">12.8</td>
<td style="text-align: left;">12.9</td>
<td style="text-align: left;">110.5</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">700</td>
<td style="text-align: left;">8.63</td>
<td style="text-align: left;">9.02</td>
<td style="text-align: left;">8.65</td>
<td style="text-align: left;">53.7</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">400</td>
<td style="text-align: left;">4.35</td>
<td style="text-align: left;">4.33</td>
<td style="text-align: left;">4.66</td>
<td style="text-align: left;">18.2</td>
<td style="text-align: left;">18.2</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">100</td>
<td style="text-align: left;">1.03</td>
<td style="text-align: left;">1.00</td>
<td style="text-align: left;">1.17</td>
<td style="text-align: left;">1.47</td>
<td style="text-align: left;">1.48</td>
<td style="text-align: left;">1.45</td>
</tr>
</tbody></table><p>As we can see, PyPy wins when the number of iterations is large.</p>
<h3 id="statistical-draws">Statistical Draws</h3><p>I use statistical Bernoulli trials (biased coin flips) extensively in the simulation. Yet, one thing that is conspicuously unavialable to PyPy users (in an easily installable format) is the scientific Python stack. Most of that boils down to <code>numpy</code>. Rather than fiddle with trying to get <code>numpy</code>, <code>scipy</code> and other packages installed, I re-implemented my own <code>bernoulli</code> function.
    ```python
    from random import random</p>
<pre><code>class bernoulli(object):
    """
    docstring for bernoulli
    """
    def __init__(self, p):
        super(bernoulli, self).__init__()
        self.p = p

    def rvs(self, num_draws):
        draws = []
        for i in range(num_draws):
            draws.append(int(random() &amp;gt; self.p))

        return draws
</code></pre>
<p>This is <em>almost</em> a drop-in replacement for <code>scipy.stats.bernoulli</code>. (The API isn't exactly the same.) I wanted to know whether the calling <code>bernoulli</code> function I wrote performed better than calling on the <code>scipy.stats</code> function. I therefore setup a series of small tests to determine at what scale of function calls it makes more sense to use PyPy vs. CPython.</p>
<p>I then wrote a simple block of code that times the Bernoulli draws. For the PyPy version:
    ```python
    from stats.bernoulli import bernoulli
    from time import time</p>
<pre><code>start = time()
bern_draws = bernoulli(0.5).rvs(10000)
mean = sum(bern_draws) / len(bern_draws)
end = time()

print(end - start)&lt;/code&gt;&lt;/pre&gt;
And for the CPython/scipy version:
&lt;pre&gt;&lt;code&gt;from scipy.stats import bernoulli
from time import time

start = time()
bern_draws = bernoulli(0/5).rvs(10000)
mean = sum(bern_draws) / len(bern_draws)   
end = time()

print(end - start)
</code></pre>
<table><colgroup> <col /> <col /> <col /> <col /> <col /> <col /> <col /> </colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Bernoulli Draws</th>
<th style="text-align: center;">PyPy + Custom (1)</th>
<th style="text-align: center;">PyPy + Custom (2)</th>
<th style="text-align: center;">PyPy + Custom (3)</th>
<th style="text-align: center;">CPython + SciPy (1)</th>
<th style="text-align: center;">CPython + SciPy (2)</th>
<th style="text-align: center;">CPython + SciPy (3)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1000000</td>
<td style="text-align: center;">0.271</td>
<td style="text-align: center;">0.241</td>
<td style="text-align: center;">0.206</td>
<td style="text-align: center;">0.486</td>
<td style="text-align: center;">0.513</td>
<td style="text-align: center;">0.481</td>
</tr>
<tr class="even">
<td style="text-align: center;">100000</td>
<td style="text-align: center;">0.0437</td>
<td style="text-align: center;">0.0421</td>
<td style="text-align: center;">0.0473</td>
<td style="text-align: center;">0.0534</td>
<td style="text-align: center;">0.0794</td>
<td style="text-align: center;">0.0493</td>
</tr>
<tr class="odd">
<td style="text-align: center;">10000</td>
<td style="text-align: center;">0.0311</td>
<td style="text-align: center;">0.0331</td>
<td style="text-align: center;">0.0345</td>
<td style="text-align: center;">0.00393</td>
<td style="text-align: center;">0.00410</td>
<td style="text-align: center;">0.00387</td>
</tr>
</tbody></table><p>As we can see, <code>scipy</code> is quite optimized, and outperforms at lower number of statistical draws. Things only become better for PyPy as the number of draws increases.</p>
<h3 id="summary">Summary</h3><p>Some things that I've learned from this exercise:</p>
<ol>
<li>For pure-Python code, PyPy can serve as a drop-in replacement for CPython.</li>
<li>Because of the JIT compiler, PyPy is blazing fast when doing iterations!</li>
<li><code>numpy</code> is not, right now, easily <code>pip</code>-installable. Because of this, the rest of the Scientific Python stack is also not <code>pip</code>-installable in a PyPy environment. (I will admit to still being a learner here - I wouldn't be able to articulate why <code>numpy</code> doesn't work with PyPy out-of-the-box. Experts chime in please?)</li>
</ol>
<p>Some things I hope will happen:</p>
<ol>
<li>Let's port the scientific Python stack code to make it PyPy compatible! (Yeah, wishful thinking...)</li>
<li>Alternatively, let's hope the <code>numba</code> project allows JIT compilation when using Python objects instead.</li>
</ol>
<p>As is the usual case for me, starting a new project idea gave me the impetus to try out a new thing, as I wouldn't have to risk breaking workflows that have worked for existing projects. If you find yourself in the same spot, I would encourage you to try out PyPy, especially for pure-Python code (i.e. no external libraries are used).</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2015/11/28/profiling-pypy-vs-python-for-agent-based-simulation/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>
  
    <h1><a href="../../../blog/2015/9/28/predicting-hiv-drug-resistance-phenotype-from-genotype/">Predicting HIV Drug Resistance Phenotype from Genotype</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2015-09-28
  </p>
  <p><strong>Note to Reader:</strong> I’d highly suggest reading this blog post on the left half of your screen, and have the <a href="https://github.com/ericmjl/hiv-resistance-prediction/blob/master/Predict%20HIV%20Genotype%20from%20Phenotype%20-%20Custom%20Funcs.ipynb">Jupyter notebook</a> on the right half of your screen. Makes things a bit easier to follow.</p>
<p>I recently have been writing a proposal to conduct some experiments to predict viral RNA polymerase activity, in some standardized unit, from protein genotype. The main application of this would be to be able to conduct quantitative surveillance in a precise fashion. For example, with HIV, as treatment progresses, the virus accumulates mutations that confer resistance. For a physician treating a patient infected with HIV, would it be possible to determine, from sequence data alone, what would be the degree of predicted viral resistance for that patient’s virus?</p>
<p>Knowing fully that this problem has been tackled many times in the past from multiple angles, I wanted to know how easily I could set up an ML workflow to go from sequence to predicted drug resistance. The goal of this blog post is to document how easy it was for me to get up and running, using Python packages really well-written Python packages.</p>
<h2 id="raw-code">Raw Code</h2><p>All of my code can be found on my Github <a href="https://github.com/ericmjl/hiv-resistance-prediction">repository</a>. You can also jump directly to the <a href="https://github.com/ericmjl/hiv-resistance-prediction/blob/master/Predict%20HIV%20Genotype%20from%20Phenotype%20-%20Custom%20Funcs.ipynb">Jupyter notebook</a> that I reference code from in this article.</p>
<h2 id="data-source-and-preprocessing">Data Source and Preprocessing</h2><p>I sourced the data from the <a href="http://hivdb.stanford.edu">Stanford HIV Drug Resistance Database</a>. Specifically, I downloaded the <a href="http://hivdb.stanford.edu/pages/genopheno.dataset.html">high quality, filtered set</a> of Genotype-to-Phenotype mappings, for protease inhibitors, nucleoside reverse transcriptase inhibitors, and non-nucleoside reverse transcriptase inhibitors. I wrote a few custom functions to preprocess the data, including the following steps:</p>
<ol>
<li>Replacing all "<code>-</code>" characters with the consensus sequences. I am guessing that they use the "<code>-</code>" character in place to help highlight where the mutations are; much more human readable.</li>
<li>Removing sequences that had more than one mutation present. Mostly a function of being lazy than anything else.</li>
<li>Removing sequences with ambiguous amino acids. These are a bit harder to deal with down the road. From biological background knowledge, it’s unlikely that excluding them would be detrmimental.</li>
<li>Dropping all conserved amino acid positions. They add nothing to the analysis.</li>
<li>Binarizing the columns. This transforms the letters of the amino acid into a first-pass feature set, in which the binarized columns indicate whether or not an amino acid is present at a given position or not.</li>
</ol>
<p>These are found in my <a href="https://github.com/ericmjl/hiv-resistance-prediction/blob/master/custom_funcs.py">custom_funcs.py</a> module, which I imported into the Jupyter notebooks. Having futzed around for about a day copying/pasting blocks of code, I refactored the code into separate functions for readability, so that only the “business logic” is shown in the notebook.</p>
<h2 id="train/test-split">Train/Test Split</h2><p>It is a standard practice to split the dataset into a training and test set. K-fold cross-validation is quite easy to do using <code>scikit-learn</code>. Given an <code>X</code> and a <code>Y</code> matrix, to split it into <code>X_train</code>, <code>X_test</code>, <code>Y_train</code>, and <code>Y_test</code>, simply do the function call:</p>
<p><code>X_train, X_test, Y_train, Y_test = train_test_split(X_binarized, Y)</code></p>
<h2 id="model-training">Model Training</h2><p>To train models, I used the <a href="http://scikit-learn.org/stable/">scikit-learn</a> package to help. It’s useful to note that <code>scikit-learn</code> has a consistent API - every regressor model has a <code>MODEL.fit()</code> and a <code>MODEL.predict()</code> function. This ‘modular’ style allowed me to wrap the series of function calls into single-line functions, and thus quickly try out a variety of models to see what out-of-box predictive power would be. Using the Random Forest Regressor as an example, I wrapped up the training and plotting phases:</p>
<p><code># Model Training</code>
<code>kwargs = {'n_jobs':-1, 'n_estimators':1000}</code>
<code>rfr, rfr_preds, rfr_mse, rfr_r2 = cf.train_model(*tts_data, model=RandomForestRegressor, modelargs=kwargs)</code></p>
<p><code># Plotting</code>
<code>cf.scatterplot_results(rfr_preds, Y_test, rfr_mse, rfr_r2, DRUG, 'Rand. Forest', figsize=std)</code></p>
<p>Here, <code>cf</code> simply refers to the <code>custom_funcs.py</code> module I wrote to refactor out the repetitive boilerplate code needed.</p>
<p>The ensemble learners also include feature importances, i.e. an identification of the columns in the data that best predict the outcome of interest. I wrapped the feature importances code to make it easy to plot:</p>
<p><code>cf.barplot_feature_importances(rfr, DRUG, 'Rand. Forest', figsize=std)</code></p>
<p>In particular, I used the ensemble learners, which are known to be pretty powerful for learning tasks. And for comparison, I pitted them against a number of linear models as well. As you can see in the notebooks, the ensemble learners outperformed the linear models, at least for a binarized amino acid feature set. This makes intuitive sense - protein sequence to function is non-linear, and highly contextual.</p>
<h2 id="neural-networks">Neural Networks!</h2><p>One of the things I wanted to highlight here was how <a href="http://danielnouri.org">Daniel Nouri’s</a> <a href="https://github.com/dnouri/nolearn">nolearn</a> package made it easy for me to start experimenting with neural networks. By no means am I a deep learning expert - I consider myself too algebra-blind (but by no means code-blind!) to learn the math behind it all. However, I know that my learning style of diving into the deep end and doing a lot of hands-on trials would help me get a fairly good intuitive grasp of how to do it. So after futzing around on a GPU cluster for a few days trying to get it configured right, I got <code>theano</code>, <code>lasagne</code> and <code>nolearn</code> up and running. (Note: A GPU makes light(er) work of training artificial neural nets. CPUs take around 5-10x more time. Highly recommended to use a GPU with neural nets. Shout-out to my PhD thesis committee member, Mark Bathe, for giving me access to his lab's GPU machine!)</p>
<p><code>nolearn</code>’s API is, by design, really close to the <code>scikit-learn</code> API. I find this to be a great thing - since neural networks are basically ML models, we get the familiar <code>neural_net.fit()</code> and <code>neural_net.predict()</code> function calls. (The importance of great APIs! Thank you, @dnouri!) The API also makes specifying a neural network architecture quite easy. For example, in the simple feed-forward network architecture that I show in the Jupyter notebook, network layers are specified as a list of parameters, and each layer’s properties can be specified by using named parameters that sync up with the specified names. The comments in my Jupyter notebook in some of the layers show my (rather simple) efforts in experimenting with different architectures. To note, the original structure of the feed-forward network is directly lifted from <a href="http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/">Daniel Nouri's tutorial</a>, so big thanks to him for publishing it!</p>
<p>FWIW, I also learned from other experienced Pythonistas (shout out to Rick Landau!) for teaching me <em>not</em> to use binary features on neural networks, something I happily disregarded for this first pass. But I’ve nonetheless still remembered that lesson! And in future iterations, probably I will try to change to non-binary features.</p>
<h2 id="summary-amp;-future-work">Summary &amp; Future Work</h2><p>So to summarize, the <code>scikit-learn</code> API makes it pretty easy to get my hands dirty doing machine learning. By keeping a <code>scikit-learn</code>-like API, <code>nolearn</code> also does a great job of keeping neural nets accessible.</p>
<p>What else do I think can be done? Well, there’s one idea I’ve been thinking about, to improve the regression score beyond what experimental error in the dataset may limit us to. Think convolutional networks (convnets) and their data input requirements. Basically, most image recognition convnets need a 2D image. But what if I used a convnet that can take in a 3D image instead? Calculating a numerical value, such as the electrostatic charge at every grid point in a static, modelled 3D protein structure, may be much more informative than simply using binarized amino acid columns. A recent paper that I read in <a href="http://www.biomedcentral.com/1471-2164/15/S5/S1">BMC genomics</a> (say "yay" for open access!) uses a computationally efficient shortcut representation to get structural features encoded as well, with great success; I would definitely be game for implementing their version as a first pass as well.</p>
<p>Apart from that, it's insufficient to run only on a single train/test split. There will always be unavoidable biases in the trained model. Training <code>k</code>-fold splits <code>k</code> times is a common practice I've heard. In papers I've read, usually k-fold splits are trained k times, and the standard deviation reported. I can imagine also doing it n times, to get a better feel for the generalization error (assuming the data are representative of the population).</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2015/9/28/predicting-hiv-drug-resistance-phenotype-from-genotype/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div>
  
    <h1><a href="../../../blog/2015/9/3/in-which-i-trained-a-neural-network/">In Which I Trained A Neural Network :)</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2015-09-03
  </p>
  <p>I have decided to link to my <a href="https://github.com/ericmjl/nnet-HA/blob/master/Prototype%20Neural%20Network%20for%20predicting%20HA%20host%20tropism.ipynb">Jupyter notebook</a> &amp; <a href="https://github.com/ericmjl/nnet-HA/tree/master">github repository</a> instead of re-writing the whole post here. I hope you enjoy it! :)</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../../../blog/2015/9/3/in-which-i-trained-a-neural-network/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  

  
  <div class="pagination">
    
      <a href="../../../blog/page/24/">&laquo; Previous</a>
    
    | 25 |
    
      <a href="../../../blog/page/26/">Next &raquo;</a>
    
  </div>


    </div>

    <nav class="navbar navbar-expand-sm navbar-light fixed-bottom bg-light">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#external-links" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="external-links">
            <ul class="navbar-nav mr-auto">
                
                <li class="nav-item">
                    <a class="nav-link" href="https://www.linkedin.com/in/ericmjl"><i class="fa fa-linkedin" aria-hidden="true"></i> LinkedIn</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://twitter.com/ericmjl"><i class="fa fa-twitter" aria-hidden="true"></i> Twitter</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://github.com/ericmjl"><i class="fa fa-github" aria-hidden="true"></i> GitHub</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://stackoverflow.com/users/1274908/ericmjl"><i class="fa fa-stack-overflow" aria-hidden="true"></i> Stack Overflow</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://shortwhale.com/ericmjl"><i class="fa fa-envelope-o" aria-hidden="true"></i> Contact Me</a>
                </li>
                
            </ul>
        </div>
    </nav>
    <!-- Boostrap JS imports -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>

</body>
