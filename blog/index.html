<!doctype html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <!-- Bootstrap v4beta Imports -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">

    <style media="screen">
        body {
            padding-top: 70px;
            padding-bottom: 70px;
        }
    </style>

    <!-- Syntax Highlighter. Use both pygments and hl.js. -->
    <link rel="stylesheet" href="../static/pygments.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- Google Analytics -->
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-12498603-2', 'auto');
        ga('send', 'pageview');
    </script>

    <!-- ClustrMaps Tracking -->
    <!-- <script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=nhKoDpoTjWz4pC6CwI-fSy4hPoJ1uXwTLCfMCT3OK_8"></script> -->

    <!-- FontAwesome embed -->
    <script src="https://use.fontawesome.com/cb9dbe8e41.js"></script>
</head>

<title>Blog - Eric J. Ma's Personal Site</title>
<body class="body">
    <nav class="navbar navbar-expand-sm navbar-light fixed-top bg-light">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#local-links" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="local-links">
            <ul class="navbar-nav mr-auto">
                
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="fa fa-home" aria-hidden="true"></i> Home</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/resume"><i class="fa fa-file-text" aria-hidden="true"></i> Resume</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/blog"><i class="fa fa-rss" aria-hidden="true"></i> Blog</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/open-source"><i class="fa fa-code" aria-hidden="true"></i> Open Source</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/projects"><i class="fa fa-briefcase" aria-hidden="true"></i> Projects</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/talks"><i class="fa fa-microphone" aria-hidden="true"></i> Talks</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/teaching"><i class="fa fa-university" aria-hidden="true"></i> Teaching</a>
                </li>
                
            </ul>
        </div>
    </nav>
    <div class="container">
        
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../static/pygments.css">
  <div>
  
    <h1><a href="../blog/2017/11/3/boston-bayesians-talk-an-attempt-at-demystifying-bayesian-deep-learning/">Boston Bayesians Talk: An Attempt at Demystifying Bayesian Deep Learning</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-11-03
  </p>
  <p>It's confirmed! I will be rehearsing my PyData NYC talk <a href="https://www.meetup.com/Boston-Bayesians/events/244731222">at Boston Bayesians</a>, held at McKinsey's office.</p>
<p>This time round, I've challenged myself with making the slides without using PowerPoint or Keynote, and I think I've successfully done it! Check them out:</p>
<ul>
<li><a href="https://github.com/ericmjl/bayesian-deep-learning-demystified">GitHub repository</a></li>
<li><a href="https://ericmjl.github.io/bayesian-deep-learning-demystified">Online slides</a></li>
</ul>
<p>Side note, I'm starting to really love what we can do with the web!</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../blog/2017/11/3/boston-bayesians-talk-an-attempt-at-demystifying-bayesian-deep-learning/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../static/pygments.css">
  <div>
  
    <h1><a href="../blog/2017/10/31/always-check-your-data/">Always Check Your Data</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-31
  </p>
  <p>True story, just happened today. I was trying to fit a Poisson likelihood to estimate event cycle times (in discreet weeks). For certain columns, everything went perfectly fine. Yet for other columns, I was getting negative infinityâ€™s likelihoods, and was banging my head over this problem for over an hour and a half.</p>
<p>As things turned out, those columns that gave me negative infinity likelihood initializations were doing so because of negative values in the data. Try fitting a Poisson likelihood, which only has positive support, on that!</p>
<p><img src="https://i.imgflip.com/1yl6ki.jpg" alt=""></p>
<p>This lost hour and a half was a good lesson in data checking/testing: <strong>always be sure to sanity check basic stats associated with the data - bounds (min/max), central tendency (mean/median/mode) and spread (variance, quartile range) - always check!</strong></p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../blog/2017/10/31/always-check-your-data/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../static/pygments.css">
  <div>
  
    <h1><a href="../blog/2017/10/27/random-forests-a-good-default-model/">Random Forests: A Good Default Model?</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-27
  </p>
  <p>I've been giving this some thought, and wanted to go out on a limb to put forth this idea:</p>
<p><strong>I think Random Forests (RF) are a good "baseline" model to try, after establishing a "random" baseline case.</strong></p>
<p>(Clarification: I'm using RF as a shorthand for "forest-based ML algorithms", including XGBoost etc.)</p>
<p>Before I go on, let me first provide some setup.</p>
<p>Let's say we have a two-class classification problem. Assume everything is balanced. One "dumb baseline"" case is a coin flip. The other "dumb baseline" is predicting everything to be one class. Once we have these established, we can go to a "baseline" machine learning model.</p>
<p>Usually, people might say, "go do logistic regression (LR)" as your first baseline model for classification problems. It sure is a principled choice! Logistic regression is geared towards classification problems, makes only linear assumptions about the data, and identifies directional effects as well. From a practical perspective, it's also very fast to train.</p>
<p>But I've found myself more and more being oriented towards using RFs as my baseline model instead of logistic regression. Here are my reasons:</p>
<ol>
<li>Practically speaking, any modern computer can train a RF model with ~1000+ trees in not much more time than it would need for an LR model.</li>
<li>By using RFs, we do not make linearity assumptions about the data.</li>
<li>Additionally, we don't have to scale the data (one less thing to do).</li>
<li>RFs will automatically learn non-linear interaction terms in the data, which is not possible without further feature engineering in LR.</li>
<li>As such, the out-of-the-box performance using large RFs with default settings is often very good, making for a much more intellectually interesting challenge in trying to beat that classifier.</li>
<li>With <code>scikit-learn</code>, it's a one-liner change to swap out LR for RF. The API is what matters, and as such, drop-in replacements are easily implemented!</li>
</ol>
<p>Just to be clear, I'm not advocating for throwing away logistic regression altogether. There are moments where interpretability is needed, and is more easily done by using LR. In those cases, LR can be the "baseline model", or even just back-filled in after training the baseline RF model for comparison.</p>
<p>Random Forests were the darling of the machine learning world before neural networks came along, and even now, remain the tool-of-choice for colleagues in the cheminformatics world. Given how easy they are to use now, why not just start with them?</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../blog/2017/10/27/random-forests-a-good-default-model/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../static/pygments.css">
  <div>
  
    <h1><a href="../blog/2017/10/11/pypy-impressive/">PyPy: Impressive!</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-11
  </p>
  <p>A few years on after trying out PyPy for the first time and wrestling with it, I still find it to be pretty awesome.</p>
<p>Now that PyPy officially supports <code>numpy</code>, I'm going to profile a few simple statistical simulation tasks:</p>
<ul>
<li>Computing the mean of a number of random number draws.</li>
<li>Simulating many coin flips</li>
</ul>
<p>I'll profile each of the tasks four ways:</p>
<ul>
<li>Pure Python implementation running from the CPython and PyPy interpreters</li>
<li><code>numpy</code> implementation running from the CPython and PyPy interpreters.</li>
</ul>
<p>So, how do PyPy and CPython fare? Let's show the results up front first.</p>
<p><a href="../blog/2017/10/11/pypy-impressive/profile.png"><img src="../blog/2017/10/11/pypy-impressive/profile-sm.png" alt="Profiling results."></a></p>
<p>Click on the image to view a higher resolution chart. The raw recorded measurements can be found <a href="https://docs.google.com/spreadsheets/d/1QB1hF7Z8SGYjvll8sYCjVYEYAgzL4pjqGt1dbO6B2Co/edit?usp=sharing">on Google Sheets</a>.</p>
<p>Here's a description of what's happening:</p>
<ul>
<li>(top-left): PyPy is approx. 10X faster than CPython at computing the mean of 10 million random numbers.</li>
<li>(top-right): When both are running <code>numpy</code>, the speed is identical.</li>
<li>(bottom-left): When simulating coin flips, PyPy with a custom <code>binomial()</code> function is about 3X faster than CPython.</li>
<li>(bottom-right): When using <code>numpy</code> instead, there is a bottleneck, and PyPy fails badly compared to CPython.</li>
</ul>
<p>It's pretty clear that when PyPy is dealing with "pure" data (i.e. not having to pass data between Python and C), PyPy runs very, very fast, and, at least in the scenarios tested here, it performs faster than the CPython interpreter. This is consistent with my previous observations, and probably explains why PyPy is very good for code that is very repetitive; the JIT tracer really speeds things up.</p>
<p>That last plot (bottom-right) is a big curiosity. Using the code below, I measured the random number generation is actually just as fast as it should be using CPython, but that PyPy failed badly when I was passing in a <code>numpy</code> array to the <code>Counter()</code> object (from the standard library). I'm not sure what is happening behind-the-scenes, but I have reached out to the PyPy developers to ask what's going on, and will update this post at a later date.</p>
<p><strong>UPDATE:</strong> I heard back from the PyPy devs <a href="https://bitbucket.org/pypy/pypy/issues/2680/slow-speed-going-from-numpy-data-structure">on BitBucket</a>, and this is indeed explainable by data transfer between the C-to-PyPy interface. It's probably parallel to the latency that arises from transferring data between the CPU and GPU, or between compute nodes.</p>
<p>So, what does this mean? It means that for pure Python code, PyPy can be a very powerful way to accelerate your code. One example I can imagine is agent-based simulations using Python objects. Another example that comes to mind is running a web server that only ever deals with strings, floats and JSONs (in contrast to matrix-heavy scientific computing).</p>
<p>Now, for those who are curious, here's the source code for the <strong>pure Python implementation of the mean of random numbers</strong>.</p>
<div class="hll"><pre><span></span><span class="c1"># Mean of 10 million random number draws.</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">n</span> <span class="o">=</span> <span class="mf">1E7</span>
<span class="n">rnds</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">)):</span>
    <span class="n">rnds</span> <span class="o">+=</span> <span class="n">random</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">rnds</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;{} seconds&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
<p>And here's the source code for the <strong><code>numpy</code> implementation of the mean of random numbers</strong>.</p>
<div class="hll"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1E7</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
<p>Next, here's the source code for <strong>coin flips in pure Python</strong>:</p>
<div class="hll"><pre><span></span><span class="c1"># Simulate 10 million biased coin flips with p = 0.3</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">rnd</span> <span class="o">=</span> <span class="n">random</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">rnd</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">False</span>


<span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">1E7</span><span class="p">))]</span>
<span class="k">print</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">result</span><span class="p">))</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
<p>And finally, source code for <strong>coin flips using <code>numpy</code></strong>:</p>
<div class="hll"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">binomial</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">coinflips</span> <span class="o">=</span> <span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1E7</span><span class="p">))</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Time for numpy coinflips: {} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">coinflips</span><span class="p">))</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} seconds&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../blog/2017/10/11/pypy-impressive/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  
    
  <!-- <div class="blog-post"> -->
  <link rel="stylesheet" href="../static/pygments.css">
  <div>
  
    <h1><a href="../blog/2017/10/10/pydata-nyc-2017/">PyData NYC 2017</a></h1>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on 2017-10-10
  </p>
  <p>I'm seriously looking forward to PyData NYC this year -- there's a great lineup of talks that I'm particularly looking forward to hearing! The theme for my set of must-see talks this year is "Bayesian machine learning" - there's much for me to learn!</p>
<p>The first is by my fellow Boston Bayesian <strong><a href="https://colindcarroll.com/">Colin Caroll</a></strong> with his talk titled <a href="https://pydata.org/nyc2017/schedule/presentation/12/">Two views on regression with PyMC3 and scikit-learn</a>. Colin is a mathematician at heart, even though he does software engineering for living now, and I can't wait to hear about regularization strategies!</p>
<p>The second is by <strong><a href="https://pydata.org/nyc2017/speaker/profile/6/">Nicole Carlson</a></strong>, with her talk titled <a href="https://pydata.org/nyc2017/schedule/presentation/24/">Turning PyMC3 into scikit-learn</a>. Nicole's talk is of interest to me because I've implemented models in PyMC3 before, and now would like to know how to make them reusable!</p>
<p>The third talk is by <strong><a href="https://pydata.org/nyc2017/speaker/profile/118/">Chaya Stern</a></strong>, with her talk titled <a href="https://pydata.org/nyc2017/schedule/presentation/53/">Bayesian inference in computational chemistry</a>. Super relevant to my work at Novartis!</p>
<p>The fourth is by my fellow Boston Pythonista <strong><a href="https://pydata.org/nyc2017/speaker/profile/34/">Joe Jevnik</a></strong>, who will be speaking on the first day about his journey into deep learning on some really cool time-series data. He works at Quantopian, BUT the spoiler here is that his talk is NOT about financial data! (I've heard his talk outline already.)</p>
<p>The fifth is a tutorial by <strong><a href="https://pydata.org/nyc2017/speaker/profile/29/">Jacob Schrieber</a></strong>, with his talk titled <a href="https://pydata.org/nyc2017/schedule/presentation/30/">pomegranate: fast and flexible probabilistic modeling in python</a>. <code>pomegranate</code>'s API models after the <code>scikit-learn</code>'s API; with the API being the user-facing interface, and <code>scikit-learn</code> being the <em>de facto</em> go-to library for machine learning, I'd be interested to see how much more <code>pomegranate</code> adds to the ecosystem, particularly w.r.t. Bayesian models.</p>
<p>There are a swathe of other good talks that I'm expecting to be able to catch online later on. <strong><a href="https://matthewrocklin.com/">Matt Rocklin</a></strong>, who is the lead developer of Dask, has done a ton of work on speeding Python up through parallelism. His talk will be on <a href="https://pydata.org/nyc2017/schedule/presentation/22/">the use of Cython & Dask to speed up GeoPandas</a>.</p>
<p>Also, <strong><a href="https://pydata.org/nyc2017/speaker/profile/80/">Thomas Caswell</a></strong>, one of the <a href="http://matplotlib.org/"><code>matplotlib</code></a> lead devs who helped guide my first foray into open source contributions, is giving a tutorial on <a href="https://pydata.org/nyc2017/schedule/presentation/3/">developing interactive figures in matplotlib</a>. Highly recommended if you're into the visualization world!</p>
<p>Finally, the always-interesting, always entertaining <strong><a href="https://pydata.org/nyc2017/schedule/presentation/25/">en zyme</a></strong> will be speaking on an <a href="https://pydata.org/nyc2017/schedule/presentation/25/">interesting topic</a>.</p>
<p>Looking forward to being at the conference, and meeting old and new friends there!</p>

  </div>

    <p><i>Did you enjoy this blog post? <a href="../blog/2017/10/10/pydata-nyc-2017/#disqus">Let's discuss more</a>!</i></p>
    <hr class="fancy">
  

  
  <div class="pagination">
    
      <span class="disabled">&laquo; Previous</span>
    
    | 1 |
    
      <a href="../blog/page/2/">Next &raquo;</a>
    
  </div>


    </div>

    <nav class="navbar navbar-expand-sm navbar-light fixed-bottom bg-light">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#external-links" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="external-links">
            <ul class="navbar-nav mr-auto">
                
                <li class="nav-item">
                    <a class="nav-link" href="https://www.linkedin.com/in/ericmjl"><i class="fa fa-linkedin" aria-hidden="true"></i> LinkedIn</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://twitter.com/ericmjl"><i class="fa fa-twitter" aria-hidden="true"></i> Twitter</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://github.com/ericmjl"><i class="fa fa-github" aria-hidden="true"></i> GitHub</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://stackoverflow.com/users/1274908/ericmjl"><i class="fa fa-stack-overflow" aria-hidden="true"></i> Stack Overflow</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://shortwhale.com/ericmjl"><i class="fa fa-envelope-o" aria-hidden="true"></i> Contact Me</a>
                </li>
                
            </ul>
        </div>
    </nav>
    <!-- Boostrap JS imports -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>

</body>
