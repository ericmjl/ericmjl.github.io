<!doctype html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <style media="screen">
        body {
            padding-top: 70px;
            padding-bottom: 70px;
        }

        /* Dark mode styles */
        body.dark-mode {
            background-color: #1a1a1a;
            color: #ffffff;
        }

        body.dark-mode .terminal {
            background-color: #1a1a1a;
            color: #ffffff;
        }

        body.dark-mode a {
            color: #66b3ff;
        }

        body.dark-mode .terminal-menu {
            background-color: #1a1a1a;
        }

        body.dark-mode .terminal-menu li a {
            color: #ffffff;
        }

        body.dark-mode .terminal-menu li a:hover {
            background-color: #333333;
        }

        /* Theme toggle button styles */
        .theme-toggle {
            position: absolute;
            top: 20px;
            right: 20px;
            z-index: 1000;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
            background-color: #f0f0f0;
            border: 1px solid #ccc;
        }

        body.dark-mode .theme-toggle {
            background-color: #333;
            color: #fff;
            border-color: #666;
        }

        .container {
            position: relative;
        }
    </style>
    
<!-- Syntax Highlighter. Use pygments. -->
<link rel="stylesheet" href="../../../../../static/pygments.css">


    

<meta property="og:title" content="A survey of how to use protein language models for protein design: Part 2">
<meta property='og:url' content='http://ericmjl.github.io/blog//blog/a-survey-of-how-to-use-protein-language-models-for-protein-design-part-2' />



    <!-- Google Analytics -->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-12498603-2', 'auto');
        ga('send', 'pageview');
    </script>

    <link rel="stylesheet" href="https://unpkg.com/terminal.css@0.7.2/dist/terminal.min.css" />
    <link rel="stylesheet" href="/static/css/custom.css" />

    <style>
        .blog-card-container {
            display: flex;
        }

        .blog-card-left {
            flex: 1;
        }

        .blog-card-right {
            flex: 3;
        }

        /* Add rounded corners to banner images */
        .banner-image {
            border-radius: 8px;
            max-width: 98%;
            height: auto;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

    </style>
    <!-- Mathjax -->
    <!-- <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
        </script>

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script> -->

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
        </script>

    <!-- Mermaid.js -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({
            startOnLoad: true,
            theme: 'neutral',
            securityLevel: 'loose'
        });
    </script>
    <style>
        .mermaid {
            background-color: white;
            padding: 1em;
            margin: 1em 0;
            border-radius: 4px;
        }
    </style>

</head>

<title>A survey of how to use protein language models for protein design: Part 2 - Eric J. Ma's Personal Site</title>

<body>
    <div class="container">
        <button class="theme-toggle" onclick="toggleTheme()">🌙</button>
        <h1 class="logo">
            <a href="/">
                Eric J Ma's Website
            </a>
        </h1>
        <!-- Top Navigation (local links) -->

        <div class="terminal-nav">
            <nav class="terminal-menu" id="local-links">
                <ul>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a href="/" rel="">Home</a>
                        
                    </li>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a class="terminal-prompt" href="/blog" rel="">Blog</a>
                        
                    </li>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a href="/books" rel="">Books</a>
                        
                    </li>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a href="/open-source" rel="">Open Source</a>
                        
                    </li>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a href="/projects" rel="">Projects</a>
                        
                    </li>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a href="/talks" rel="">Talks</a>
                        
                    </li>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a href="/teaching" rel="">Teaching</a>
                        
                    </li>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a href="/user-manual" rel="">User Manual</a>
                        
                    </li>
                    
                    <li class="menu-item">
                        <!-- Set blinking cursor correctly on navigation -->
                        
                        
                        
                        
                        
                        <a href="/bio" rel="">Bio</a>
                        
                    </li>
                    
                </ul>
            </nav>
        </div>

        <!-- Body -->
        <div id="body">
            


<div class="terminal-card">
  <header id="post_title" name="post_title">
<!-- Set title style -->
<span name="title" id="title">A survey of how to use protein language models for protein design: Part 2</span>
</header>
  <div class="card-body">
    
<!-- Append author -->
<small>
  <p>
    written by
    
    <a class="author" href="https://twitter.com/ericmjl">Eric J. Ma</a>
    
    on
    <span id="pub_date" name="pub_date">2024-08-02</span>

    
    | tags:
    <!-- Append tags after author -->
    <span class="boxed" id="tags" name="tags">
      <a class="tags" href="../../../../tag/protein modeling/">
        protein modeling
      </a>
    </span>
    <span class="boxed" id="tags" name="tags">
      <a class="tags" href="../../../../tag/machine learning/">
        machine learning
      </a>
    </span>
    <span class="boxed" id="tags" name="tags">
      <a class="tags" href="../../../../tag/bioinformatics/">
        bioinformatics
      </a>
    </span>
    <span class="boxed" id="tags" name="tags">
      <a class="tags" href="../../../../tag/data science/">
        data science
      </a>
    </span>
    <span class="boxed" id="tags" name="tags">
      <a class="tags" href="../../../../tag/protein engineering/">
        protein engineering
      </a>
    </span>
    <span class="boxed" id="tags" name="tags">
      <a class="tags" href="../../../../tag/autoregressive training/">
        autoregressive training
      </a>
    </span>
    <span class="boxed" id="tags" name="tags">
      <a class="tags" href="../../../../tag/masked language modeling/">
        masked language modeling
      </a>
    </span>
    
  </p>
  
</small>

    <hr>

    
    
    <img src="logo.webp" class="banner-image" >
    

    <!-- NOTE: I am keeping this here just for preview purposes.
     We must rely on the webp logo for the blog post.
     Pre-commit hooks will ensure that the png logo is converted to webp.-->
    

    
    <div class="blog-summary">
      <i><p>In part 2 of my three-part series on PLMs in protein engineering, I do a deep dive into the training methods of protein language models, specifically focusing on masked language modeling and autoregressive training. I explain how these models are trained, highlighting the complexities and considerations involved in training, such as model choice, masking fraction, and the need for curated training sets. With these insights, I aim to shed light on the intricate process of preparing protein language models for protein design. Curious about how these models could revolutionize protein engineering?</p>
</i>
    </div>
    

    <span id="post_body" name="post_body">
      <p><strong>This is part 2 of my series on protein language models.
If you're looking for part 1,
please find it <a href="https://ericmjl.github.io/blog/2024/7/26/a-survey-of-how-to-use-protein-language-models-for-protein-design-part-1/">here</a>.</strong></p>
<h2 id="how-exactly-are-protein-language-models-trained">How exactly are protein language models trained?</h2><p>If you're familiar with how natural language models are trained, then this should come as no surprise to you: protein language models are trained in exactly the same way! There are generally two ways to train a protein language model: <strong>masked language modelling</strong> and <strong>autoregressive training</strong>. I will provide a brief overview of these training methods.</p>
<h3 id="masked-language-modeling">Masked Language Modeling</h3><p>Masked language modelling training can be thought of like this:</p>
<ol>
<li>taking a protein sequence</li>
<li>mask out a fraction of the positions - we call this the <strong>masked sequence</strong></li>
<li>pass the masked sequence into the masked language model and have it predict what amino acid letter should have been at the masked position, given the rest of the un-masked letters</li>
<li>score the performance by measuring how wrong the model was</li>
</ol>
<p>That’s it!</p>
<p>To prepare the training data, we would using Python code that looks like this:</p>
<div class="hll"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mask_amino_acid_sequence</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">fraction</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">fraction</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Fraction must be between 0 and 1.&quot;</span><span class="p">)</span>

    <span class="n">sequence_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
    <span class="n">total_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence_list</span><span class="p">)</span>
    <span class="n">num_to_mask</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_length</span> <span class="o">*</span> <span class="n">fraction</span><span class="p">)</span>
    <span class="n">indices_to_mask</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">total_length</span><span class="p">),</span> <span class="n">num_to_mask</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices_to_mask</span><span class="p">:</span>
        <span class="n">sequence_list</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;-&#39;</span>

    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sequence_list</span><span class="p">)</span>
</pre></div>
<p>This thus produces training set sequences that look like this (this example has 15% of sequences randomly masked):</p>
<div class="hll"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;masked_sequence&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;MD-DIAA-VV-NGSGMCKAG-AGDDAP-AVFP-IVGRPRHQGVMV-MGQKDSYVGDEAQSKR-ILTLKYP-EH-IVTNWDD-EKIWHHTF--ELRVA-E--PVLLTEAPL--KAN-EKMT-IMFETFNTPAMYVAIQ-VLSL--SGRTT-IVMDS--GVTHTVPIYEGYALPHAILRL-LAGRDLT-YL-KILTE-GYSFTTTAEREIVR--KE-L-YVALDFEQE-ATAASSSSLEKSY-LP-GQVI-IGNE-FRCPEAL-QPSF-GME-CGIHETTFN-IMK-DV-I-KDLYANTV-SGGTTMYPGIADRMQ-E-TALAPSTM-IKIIAP-ERKYS-WIG-SIL-SLSTFQQMWI-KQEYDESGPSIV-RKCF&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;original_sequence&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;MDDDIAALVVDNGSGMCKAGFAGDDAPRAVFPSIVGRPRHQGVMVGMGQKDSYVGDEAQSKRGILTLKYPIEHGIVTNWDDMEKIWHHTFYNELRVAPEEHPVLLTEAPLNPKANREKMTQIMFETFNTPAMYVAIQAVLSLYASGRTTGIVMDSGDGVTHTVPIYEGYALPHAILRLDLAGRDLTDYLMKILTERGYSFTTTAEREIVRDIKEKLCYVALDFEQEMATAASSSSLEKSYELPDGQVITIGNERFRCPEALFQPSFLGMESCGIHETTFNSIMKCDVDIRKDLYANTVLSGGTTMYPGIADRMQKEITALAPSTMKIKIIAPPERKYSVWIGGSILASLSTFQQMWISKQEYDESGPSIVHRKCF&quot;</span>
<span class="p">},</span>
<span class="err">...</span>
</pre></div>
<p>And so the model is trained, over thousands to millions of examples, with the dataset designed by a data scientist, to reconstruct the original sequence from the masked sequence.</p>
<p>Examples of models that were trained this way include:</p>
<ul>
<li><a href="https://github.com/microsoft/protein-sequence-models">CARP</a>, by Microsoft Research, and</li>
<li><a href="https://github.com/facebookresearch/esm">ESM 1 and 2</a>, by Meta AI, and now Evolutionary Scale (<a href="https://github.com/evolutionaryscale/esm">ESM3</a>)</li>
</ul>
<p>To use the model for generating new sequences, one starts out by masking out a fraction of positions and calculating the probability of an amino acid at each masked position. Then, one has a choice:</p>
<ul>
<li><strong>Independent Sampling:</strong> Either sample all masked positions at one shot, or</li>
<li><strong>Iterative Decoding:</strong> Iteratively sample a subset of masked positions, recalculate the positional probabilities, and repeat sampling until all positions are sampled.</li>
</ul>
<p>Independent sampling assumes that the amino acid probabilities per position are independent of one another, while the iterative decoding allows for conditional dependence on previously sampled positions. For the technically-minded, the second is akin to an MCMC sample across all potential position-wise conditional dependencies, and in spirit looks similar to the next method we will discuss.</p>
<h3 id="autoregressive-training">Autoregressive Training</h3><p>Autoregressive training is another way of training a protein language model. Here, the model is trained with a "prompt", which, depending on the model goal, can be different. One example might be setting up the training data set by prompting with a natural language description of the protein and getting back a generated protein sequence, as seen below:</p>
<div class="hll"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;This protein forms building blocks of intracellular cytoskeleton.&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;generated&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;MDDDIAALVVDNGSGMCKAGF...*&quot;</span>
<span class="p">}</span>
</pre></div>
<p>But what I have seen more commonly done is prompting with the first N amino acids of a sequence and asking the model to generate the rest of the sequence:</p>
<div class="hll"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;MDDDIAALVVDNGSGMCKAGF&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;generated&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AGDDAPRAVFPSIVGRPRHQGVMVGMGQKDSYVGDEAQSKRGILTLKYPIEHGIVTNWDDMEKIWHHTFYNELRVAPEEHPVLLTEAPLNPKANREKMTQIMFETFNTPAMYVAIQAVLSLYASGRTTGIVMDSGDGVTHTVPIYEGYALPHAILRLDLAGRDLTDYLMKILTERGYSFTTTAEREIVRDIKEKLCYVALDFEQEMATAASSSSLEKSYELPDGQVITIGNERFRCPEALFQPSFLGMESCGIHETTFNSIMKCDVDIRKDLYANTVLSGGTTMYPGIADRMQKEITALAPSTMKIKIIAPPERKYSVWIGGSILASLSTFQQMWISKQEYDESGPSIVHRKCF*&quot;</span>
<span class="p">}</span>
</pre></div>
<p>Examples of such protein language models include:</p>
<ul>
<li><a href="https://github.com/salesforce/progen">ProGen</a> by Salesforce AI, which was <a href="https://www.biorxiv.org/content/10.1101/2024.04.22.590591v1">used by Profluent to design OpenCRISPR1</a></li>
<li><a href="https://github.com/dauparas/ProteinMPNN">ProteinMPNN</a> by Baker Lab (UW)</li>
</ul>
<h2 id="wait-are-the-training-paradigms-really-that-simple">Wait, are the training paradigms really that simple?</h2><p>Good instincts! I've made some simplifications above to introduce the training paradigm, but that means I've masked out (pun intended!) some of the complexities in training these models. Here are a few considerations that one needs to think about when training these models and designing their training data.</p>
<h3 id="decision-1-which-modelling-paradigm">Decision 1: Which modelling paradigm?</h3><p>The first is to choose which model family to use. As you probably can tell, the masked language modelling paradigm fits naturally with sampling point mutations across the sequence. On the other hand, autoregressive generation fits quite naturally with a <em>de novo</em> design paradigm, where one prompts with the N-terminus of a protein and ask the model to generate the rest of the protein.</p>
<p>With the right training modifications, it is possible have an autoregressive model generate sequences in the C-to-N direction (rather than N-to-C); this entails training the model with sequences reversed. It is also possible to train a masked language model to do larger-scale edits, such as by masking 80-90% of a sequence randomly and training the model to reconstruct them.</p>
<h3 id="decision-2-what-fraction-to-mask/prompt">Decision 2: What fraction to mask/prompt?</h3><p>If doing masked language modelling, one must ask the question: how much of a sequence should we mask? Do we follow convention and only mask 10-30% of a sequence? Or do we go more aggressively and mask a large fraction of the sequence? Is there a threshold at which masking too much becomes infeasible?</p>
<p>Or if we are doing autoregressive training, how much prompting do we do? Do we prompt it with only 10 amino acids, or do we prompt it with 50? Keep in mind that even though autoregressive generation is stochastic after the prompt, the prompt remains constant. Is this a desirable property? Or will this cause issues with the diversity of sequences needed?</p>
<p>Another question for autoregressive generation: when a model is used to autoregressively generate sequences, it needs to know when to stop. Most commonly, this is done by asking the model to predict when it should sample a stop character (which would likely be the <code>*</code> character, if we adopt standard protein bioinformatics convention), but the model developer can also choose to set lower-bound and upper-bound limits for the protein sequence length. Essentially, the for-loop for generation could look something like this (for upper-bound limits):</p>
<div class="hll"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_sequence_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="n">sequence</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">sequence</span> <span class="o">+=</span> <span class="n">prompt</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_sequence_length</span><span class="p">):</span>
        <span class="n">new_char</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">sequence</span> <span class="o">+=</span> <span class="n">new_char</span>
        <span class="k">if</span> <span class="n">new_char</span> <span class="o">==</span> <span class="s2">&quot;*&quot;</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">sequence</span>
</pre></div>
<h3 id="decision-3-do-we-need-to-curate-our-own-training-set-to-train-our-own-model">Decision 3: Do we need to curate our own training set (to train our own model)?</h3><p>Profluent spent a lot of effort curating an expanded CRISPR-Cas9 training set for its language models, while the Protein Informatics Group at Oxford (led by Charlotte Dean) did a similar thing for the Observed Antibody Space (with its openly released AbLang and AbLang2 models). One question can be asked: is it worth our time to generate a training set for our own protein?</p>
<p>I think the answer depends both on the goals of the protein engineering campaign and the known sequence diveristy of the protein to be engineered. For example, if a protein is either (a) known to be present across the tree of life (i.e. it has highly evolutionarily conserved homologues) or (b) has undergone known gene duplication with sequence drift (i.e. it has known paralogues), then a protein family-specific model can be a useful thing to do, especially if one can curate on the order of thousands to millions of diverse sequences. On the other hand, if there is little known diversity (even after trying BLAST and HMMer searches of sequence databases), it may be more prudent to sample directly from the language model itself.</p>
<p>I'll also note here that curating the training set often involves making judgment calls that are challenging to revisit later. Examples include deciding what e-value to use as a cutoff when doing a BLAST search or deciding on a likelihood threshold when using HMMer. The effect of these decisions on the performance of generated protein sequences is almost impossible to divine without doing multiple rounds of laboratory experiments, and this might not even be the highest-value thing to worry about. As such, these are often left as judgment calls that are documented but not necessarily justified.</p>
<h3 id="decision-4-fine-tuning-hyperparameters">Decision 4: Fine-tuning hyperparameters</h3><p>If one decides to do a custom-trained (a.k.a. fine-tuned) model, then the usual neural network model training concerns become things to consider. These include training hyperparameters, such as the number of epochs, learning rate, etc. Thankfully, fine-tuning a model implies keeping <em>model hyperparameters</em> constant, so we have one less concern to consider.</p>
<p>To the best of my knowledge, no theory dictates what ought to be the best hyperparameters, so it's often down to running computational experiments to decide which ones to use empirically. Running experiments implies identifying metrics to evaluate the model, which can be tricky: a generative model's training metrics (such as final loss score) may not necessarily indicate what we care about (the performance of generated sequences). This implies that much thought is needed to develop good leading indicators of modelling strategy performance. (More on that later -- the reality of the wet lab places constraints on how many computational modelling decisions we can iterate on!)</p>
<h3 id="outlook-on-these-questions">Outlook on these questions</h3><p>I don't think the answers to these questions are well-known. My only guide is to (a) train the model in the way it's intended to be used and (b) ensure that its intended use is also in line with the goals of the protein engineering campaign.</p>
<p>Up next is <a href="https://ericmjl.github.io/blog/2024/8/9/a-survey-of-how-to-use-protein-language-models-for-protein-design-part-3/">part 3</a> of this series, in which we discuss how we can evaluate generated sequences from protein language models, and how to work with wet lab teams.</p>

    </span>

    
    
    
    
    

    <hr>

    <i>Cite this blog post:</i>
    <div class="hll" style="position: relative;">
    <button class="copy-button" onclick="copyCitation()" title="Copy citation">
      <span class="copy-icon">📋</span>
    </button>
    <pre>
<span id="citation-text"><span><span style="color: darkblue; font-weight: bold">@article</span>{
    <span style="color: black; font-weight: bold">ericmjl-2024-a-survey-of-how-to-use-protein-language-models-for-protein-design-part-2</span>,
    <span style="color: green; font-weight:bold">author</span> = <span style="color: maroon">{Eric J. Ma}</span>,
    <span style="color: green; font-weight:bold">title</span> = <span style="color: maroon">{A survey of how to use protein language models for protein design: Part 2}</span>,
    <span style="color: green; font-weight:bold">year</span> = <span style="color: maroon">{2024}</span>,
    <span style="color: green; font-weight:bold">month</span> = <span style="color: maroon">{08}</span>,
    <span style="color: green; font-weight:bold">day</span> = <span style="color: maroon">{02}</span>,
    <span style="color: green; font-weight:bold">howpublished</span> = <span style="color: maroon">{\url{https://ericmjl.github.io}}</span>,
    <span style="color: green; font-weight:bold">journal</span> = <span style="color: maroon">{Eric J. Ma's Blog}</span>,
    <span style="color: green; font-weight:bold">url</span> = <span style="color: maroon">{https://ericmjl.github.io/blog/2024/8/2/a-survey-of-how-to-use-protein-language-models-for-protein-design-part-2}</span>,
}
  </span></pre>
    </div>

    <script>
    function copyCitation() {
      const citationElement = document.getElementById('citation-text');
      const text = citationElement.textContent;

      // Create a temporary textarea element
      const textarea = document.createElement('textarea');
      textarea.value = text;
      document.body.appendChild(textarea);

      // Select and copy the text
      textarea.select();
      document.execCommand('copy');

      // Remove the temporary textarea
      document.body.removeChild(textarea);

      // Visual feedback
      const button = document.querySelector('.copy-button');
      const originalText = button.innerHTML;
      button.innerHTML = '<span class="copy-icon">✓</span>';
      button.style.backgroundColor = '#4CAF50';

      // Reset button after 2 seconds
      setTimeout(() => {
        button.innerHTML = originalText;
        button.style.backgroundColor = '';
      }, 2000);
    }
    </script>

    <style>
    .copy-button {
      position: absolute;
      top: 8px;
      right: 8px;
      background-color: transparent;
      color: #666;
      border: none;
      padding: 4px 8px;
      border-radius: 4px;
      cursor: pointer;
      font-size: 14px;
      transition: all 0.3s ease;
      z-index: 1;
    }

    .copy-button:hover {
      background-color: rgba(0, 0, 0, 0.1);
      color: #333;
    }

    .copy-icon {
      font-size: 14px;
    }
    </style>
    <hr>
    <p>
      <i>I send out a newsletter with tips and tools
        for data scientists. Come check it out at
        <a href="https://dspn.substack.com">Substack</a>.</i>
    </p>
    <p>
      <i><span>If you would like to sponsor the coffee that goes into making my posts,
        please consider </span>
        <a href="https://github.com/sponsors/ericmjl">GitHub Sponsors</a>!</i>
    </p>
    <p>
      <i><span>Finally, I do free 30-minute GenAI strategy calls for teams
        that are looking to leverage GenAI for maximum impact. Consider </span>
        <a href="https://calendly.com/ericmjl/llm-chat">booking a call on Calendly</a>
        if you're interested!</i>
      </i>
    </p>
  </div>
  <div class="giscus" id="giscus-container"></div>
  <script>
    // Determine theme from localStorage or fallback to light
    var theme = localStorage.getItem('theme') === 'dark' ? 'dark' : 'light';
    var giscusScript = document.createElement('script');
    giscusScript.src = 'https://giscus.app/client.js';
    giscusScript.setAttribute('data-repo', 'ericmjl/website');
    giscusScript.setAttribute('data-repo-id', 'MDEwOlJlcG9zaXRvcnk2MDIzMzAxNg==');
    giscusScript.setAttribute('data-category', 'Comments');
    giscusScript.setAttribute('data-category-id', 'DIC_kwDOA5cVOM4Crqx4');
    giscusScript.setAttribute('data-mapping', 'pathname');
    giscusScript.setAttribute('data-strict', '1');
    giscusScript.setAttribute('data-reactions-enabled', '1');
    giscusScript.setAttribute('data-emit-metadata', '0');
    giscusScript.setAttribute('data-input-position', 'top');
    giscusScript.setAttribute('data-theme', theme);
    giscusScript.setAttribute('data-lang', 'en');
    giscusScript.crossOrigin = 'anonymous';
    giscusScript.async = true;
    document.getElementById('giscus-container').appendChild(giscusScript);
  </script>
</div>



        </div>

        <!-- Bottom Navigation (external links) -->
        <div class="terminal-nav">
            <nav class="terminal-menu" id="local-links">
                <ul>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="https://ericmjl.github.io/resume" rel="">
                            Resume</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="https://www.linkedin.com/in/ericmjl" rel="">
                            LinkedIn</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="http://github.com/ericmjl" rel="">
                            GitHub</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="https://ericmjl--shortmail-run-app.modal.run/send/cce87ae9c1d7" rel="">
                            Contact Me</a>
                    </li>
                    
                    <li class="nav-item">
                        <a class="nav-link" href="https://ericmjl.github.io/blog.xml" rel="">
                            Blog RSS</a>
                    </li>
                    
                </ul>
            </nav>
        </div>

    </div>

    <script>
        // Theme toggle functionality
        function setGiscusTheme(theme) {
            const iframe = document.querySelector('iframe.giscus-frame');
            if (!iframe) return;
            iframe.contentWindow.postMessage(
                {
                    giscus: {
                        setConfig: {
                            theme: theme
                        }
                    }
                },
                'https://giscus.app'
            );
        }

        function toggleTheme() {
            const body = document.body;
            const themeToggle = document.querySelector('.theme-toggle');

            if (body.classList.contains('dark-mode')) {
                body.classList.remove('dark-mode');
                themeToggle.textContent = '🌙';
                localStorage.setItem('theme', 'light');
                setGiscusTheme('light');
            } else {
                body.classList.add('dark-mode');
                themeToggle.textContent = '☀️';
                localStorage.setItem('theme', 'dark');
                setGiscusTheme('dark');
            }
        }

        // Check for saved theme preference
        document.addEventListener('DOMContentLoaded', () => {
            const savedTheme = localStorage.getItem('theme');
            const themeToggle = document.querySelector('.theme-toggle');

            if (savedTheme === 'dark') {
                document.body.classList.add('dark-mode');
                themeToggle.textContent = '☀️';
                setTimeout(() => setGiscusTheme('dark'), 500);
            } else {
                setTimeout(() => setGiscusTheme('light'), 500);
            }
        });
    </script>
</body>
